\section{Optimizing Pointwise Convolution}
\label{sec:pwconv} In this section, we explain the workflow of our dynamic tile size scheme for pointwise convolution.
Our dynamic tile size scheme will search for the optimal tile size for the output based on the size of input and generate a proper number of tiles to saturate GPU and maximize data reuse.
Our approach consists of three stages, described as follows.

In the first and second stages, we identify parameters related to the tile size and determine candidate values for each parameter. The first and second stages process input dependent and independent parameters respectively. 
In the third stage, as detailed in Algorithm \ref{algo:pwalgo}, we iterate over all combinations of parameters and search for the combination that achieves optimal SM utilization and data reuse.   


In the following sections, we give a detailed description of three stages. 
\subsection{Determine Candidates for Input Dependent Parameters}
In our design, we use a 2-level tiling method, as shown in Fig. \ref{fig:pwworkflow}, to partition the output into block tiles and warp tiles.
Each thread block processes one block tile and each warp processes one warp tile.
The height dimension of the warp tile is shared among 32 threads of a warp and the width dimension of the warp tile is distributed across 32 threads of a warp.
Hence, we have two input dependent parameters, namely the height and width of the warp tile, denoted as $Warp_H$ and $Warp_W$ respectively.
Now we introduce how to use the 2-level tiling method to determine candidate values for $Warp_H$ and $Warp_W$. 

To divide the output into block tiles, we utilize two logical layouts of the output, \textbf{\emph{L1}} and \textbf{\emph{L2}}, as shown in Fig. \ref{fig:pwworkflow}.
$F_N$ and $I_N \times I_H \times I_W$ represent the filter and input dimensions of the output respectively.
Before partitioning the output, we first select the layout of the output based on the size of the filter dimension.
The rationale behind choosing the filter dimension instead of the input dimension can be described as follows.
The number of filters, $F_N$, is fixed once the structure of a CNN is determined.
But the size of the input dimension will be affected by the batch size, $I_N$, during inference and training.
Therefore, it is easier to design our approach based on the size of the filter dimension.
When $F_N > 48$, we choose layout \textbf{\emph{L1}} and distribute filter channels across threads within a warp.
Otherwise, we choose layout \textbf{\emph{L2}} and distribute input channels.
The boundary $F_N = 48$ is determined as follows.
Fig. \ref{fig:pwworkflow} demonstrates that in layout \textbf{\emph{L2}}, the maximal value of $F_N$ is $4 \times Warp_H$ and $Warp_H \leq 12$ (explain later in this section), therefore we have $F_N \leq 48$ for layout \textbf{\emph{L2}}.

Since both layouts have the similar procedure, we take layout \textbf{\emph{L1}} as an illustration example and give a brief description of layout \textbf{\emph{L2}} at the end of this section.
After choosing the layout based on $F_N$, we partition the output along the filter dimension.
First, we halve the filter dimension if $F_N \geq 512$.
The reason is that if we let each thread block process a large number of filters, then each thread needs to issue more than 15 global memory load instructions, which may cause MIO (Memory Input Output) instruction queue throttle and leads to performance degradation.
Then, we halve both dimensions of each block tile and generate $2 \times 2$ warp tiles.

Based on the partition method, we know that $Warp_W$ can be calculated with $Warp_W=F_N/4$ or $Warp_W=F_N/2$. Thus, we only need to determine candidate values for $Warp_H$ based on the size of the input dimension.
In our design, when $Warp_H > 12$, we need assembly level optimizations like the work in
\cite{yan2020optimizing,yan2020demystifying} for some configurations of pointwise convolutions to avoid register spills. But in this work,
we focus on higher level rather than assembly level optimizations, and thus set $Warp_H \leq 12$.
If the size of the input dimension is large, we prefer to choose a large $Warp_H$ because using small $Warp_H$ will generate many thread blocks and results in multiple loads of shared filters \cite{jia2020enabling, zheng2020flextensor}.
If the size of the input dimension is small, we prefer to choose a small $Warp_H$ because using a large $Warp_H$ will generate a few thread blocks and result in SM underutilization.
Since each thread loads at most 12 input elements ($Warp_H \leq 12$), we set the upper limit of large $Warp_H$ to 12 and the lower limit to $12/2=6$.
Therefore, the candidates for large $Warp_H$ are $Warp_H=\{6,7,8,9,10,11,12\}$.
The candidates for small $Warp_H$ are $Warp_H=\{2,3,4,5,6,7,8\}$.
In our experiments, there is no clear boundary between large and small candidate sets of $Warp_H$, therefore we let both sets overlap in the middle values.
The boundary between the large and small size of the input dimension is experimentally determined as $I_N \times I_H \times I_W=16 \times 14 \times 14$.

Compared to layout \textbf{\emph{L1}}, layout \textbf{\emph{L2}} swaps the input and filter dimensions. Hence, $Warp_H$ can be calculated with $Warp_H=F_N/4$ or $Warp_H=F_N/2$. The candidate values for large $Warp_W$ are $Warp_W=\{6,7,8,9,10,11,12\}$ and for small $Warp_W$ are $Warp_W=\{2,3,4,5,6,7,8\}$.

\subsection{Determine Candidates for Input Independent Parameters}
There are three input independent parameters we need to consider, namely the number of warps in a thread block ($Warp_{num}$), the number of thread blocks that can run concurrently on an SM ($Block_{num}$) and the number of channels to be distributed ($C_{num}$).

When determining candidates for $Warp_{num}$, we need to consider (1) a small warp number will decrease the opportunity to hide the memory access latency at the warp level, (2) a large warp number will decrease the number of thread blocks and may lead to SM underutilization. 
We empirically set the warp number to be four ($Warp_{num}=4$), which gives good performance on our pilot study using microbenchmarks of hand-written pointwise convolution kernels. 
For the number of thread blocks, $Block_{num}$, we use two values, 2 and 4, on our evaluation platforms. 
These choices are justified as follows. For Nvidia GPUs, each GPU thread can use up to 255 registers, and each SM has 65,536 registers. 
If we set $Block_{num}=1$ and $Warp_{num}=4$ (per our discussion above), each SM will have $Block_{num} \times Warp_{num}=4$ wraps. 
This allows a thread block to use up to just half of the available registers of an SM because a thread block under this setting can use at most $4\ (warps\ in\ an\ SM) \times 32\ (threads\ per\ warp) \times 255\ (registers\ per\ thread)=32,640$ registers. 
Therefore, to utilize the available hardware register, one should set $Block_{num}$ to be greater than one. 
We also found that setting $Block_{num}>4$ during searching offers little benefit and hence we set the $Block_{num}$ to be either 2 or 4 ($Block_{num}=\{2,4\}$).

%To achieve the best performance, we iterate over all candidate combinations of $Block_{num}$, $C_{num}$ and $Warp_H$, and select the combination that leads to optimal SM utilization and arithmetic intensity.

When searching for the optimal combination of parameters, a small tile size may be generated, which may lead to low arithmetic intensity and can not hide global memory access latency.
 For example, we assume that the warp tile size is $Warp_H \times Warp_W = 8 \times 64$ and has 56 channels, which means that one warp needs to convolve 8 input elements with 64 filter elements and accumulates results 56 times to generate $8 \times 64=512$ elements. Since the height dimension is shared among 32 threads of the warp, each thread loads 8 input elements, and width dimension is distributed across 32 threads, each thread loads 2 filter elements. Therefore, each thread accumulates 56 channels of $8 \times 2=16$ elements. Now we can estimate arithmetic intensity of each thread for one iteration as $\frac{number\ of\ multiplications}{number\ of\ elements}=\frac{8 \times 2}{8 + 2}=1.6$. We can improve arithmetic intensity by distributing channels across threads, as shown in Fig. \ref{fig:pwworkflow}. We distribute eight channels ($C_{num}=8$) of each filter element across 32 threads of the warp. 
 In that case, each warp can process $F_{num}=32/C_{num}=32/8=4$ filter elements and each thread processes $T_{num}=Warp_W/F_{num}=64/4=16$ filter elements.
 The arithmetic intensity can be estimated as $\frac{Warp_H \times T_{num}}{Warp_H + T_{num}}=\frac{8 \times 16}{8+16}=5.3$.
 Higher arithmetic intensity increases the chance to hide global memory access latency.
To fully utilize a warp, candidate values for $C_{num}$ should be a power of 2.
Thus, candidates for $C_{num}$ are $C_{num}=\{1,2,4,8,16,32\}$.


\subsection{Searching For the Optimal Combination}
When searching for the optimal combination, we only consider combinations that satisfy hardware resources constraints, including registers and shared memory.
In the rest of this section, we take layout \textbf{\emph{L1}} as an illustration example.
Based on $Block_{num}$, we calculate the number of registers each thread can use ($Limit_R$) and the size of shared memory each thread block can use ($Limit_S$) with formulas $Limit_R=Total_R/(Block_{num}\times Warp_{num} \times 32)$ and $Limit_S=Total_S/Block_{num}$ respectively. $Total_R$ and $Total_S$ represent the number of registers and the size of shared memory of an SM, respectively. On RTX 2080Ti, $Total_R=65536$ and $Total_S=64KB$ while  on Jetson AGX Xavier, $Total_R=65536$ and $Total_S=48KB$.

In our approach, each warp processes one warp tile which contains $Warp_W \times Warp_H$ output elements.
Each thread calculates $Warp_H \times T_{num}$ elements and thus needs $R_{result}=Warp_H \times T_{num}$, $R_{operand}=Warp_H+T_{num}$ registers to store results and operands respectively.
%In cases where the computational workload is small, we try to let each thread accumulates $Warp_H \times T_{num}$ output elements $k \in \{1,2,3,4\}$ times.
The constraints can be formulated as follows:
\begin{equation}\nonumber
R_{tmp}=\frac{C_{num} \times 2 \times Warp_W}{128}+\frac{C_{num}  \times 2 \times Warp_H}{128}
\end{equation}
\begin{equation}
    \label{fo:limitr}
R_{result}+R_{operand}+R_{tmp}+extraR \leq Limit_R
\end{equation}
\begin{equation}
    \label{fo:limits}
(2 \times Warp_H+2 \times Warp_W)\times C_{num} \times 4 \times 2 \leq Limit_S
\end{equation}
where $R_{tmp}$ is the number of temporary registers used to store filter and input elements loaded from global memory.
$2 \times Warp_W$ and $2 \times Warp_H$ represent the width and height of the block tile respectively. 128 means each thread block has $Warp_{num} \times 32 = 4 \times 32=128$ threads to load data from global memory. 
In Formula \ref{fo:limitr}, $extraR$ is the number of additional registers allocated by the compiler and its value is determined through an off-line method. In Formula \ref{fo:limits}, 4 means each element has 4 bytes and 2 means we use a double buffer method.
\begin{figure*}
	\centering
    \includegraphics[width=0.95\textwidth,height=7cm]{./figure/pwworkflow.eps}
    \caption{Workflow of our 2-level partition and channel distribution methods.} \label{fig:pwworkflow}
\end{figure*}
\begin{algorithm}[t!]
    \small
        \KwIn{$I$, $F$}
        \KwOut{$O$}
        \tcp{below codes are executed on CPU}        
        $Warp_{num} \gets 4$, $Block_{num} \gets \{2,4\}$\;
        $C_{num} \gets \{1,2,4,8,16,32\}$\;
        
        Choose the layout and partition the output based on $F_N$\;
        Choose the candidate set for $Warp_H$ ($Warp_W$) based on the size of input dimension\;
        $preSM \gets MAX\_FLOAT$,$preAI \gets MIN\_INT$\;
        \ForEach{combination of $Warp_W$, $Warp_H$, $Warp_{num}$, $Block_{num}$ and $C_{num}$}{
            \If{not satisfy constraints of Formula \ref{fo:limitr} and \ref{fo:limits}}{
                continue\;
            }
            Calculate $SM_{util}$ and $AI$ with Formula \ref{fo:smutil} and \ref{fo:diff}\;
            \If{$preSM \geq 1$ and $SM_{util} \geq 1$ and ((both are close and $AI>preAI$) or ($SM_{util}<preSM$))}{
                    $preSM \gets min(preSM,SM_{util})$\;
                    $preAI \gets AI$, record the combination\;
            }
            \ElseIf{$SM_{util}<1$ and ((both are close and $AI>preAI$) or ($SM_{util}>preSM$))}{
                    $preSM \gets max(preSM,SM_{util})$\;
                    $preAI \gets AI$, record the combination\;
            }

        }
        
        Choose the proper kernel based on the recorded combination.\;
        \tcp{below codes are executed on GPU}
        Each thread block loads $C_{num}$ channels of the needed input and filter into shared memory array $sharedBuf1$\;
        $\_\_syncthreads()$\;
        \For{$iter \gets 0$ \KwTo $I_C$ By $2 \times C_{num}$}{
            Load next $C_{num}$ channels of input and filter into temporary registers\;
            Load current channels of input and filter from $sharedBuf1$ into registers\;
            Accumulate output elements\;
            Write temporary registers into shared memory $sharedBuf2$\;
            $\_\_syncthreads()$\;
            Repeat above steps but swap $sharedBuf1$ and $sharedBuf2$\;
        }
        Use segmented parallel reduce to get the final output elements and write the result to $O$\;
        \caption{Pointwise Convolution Optimization}
        \label{algo:pwalgo}
\end{algorithm}

To guide the search for the optimal combination of parameters, we use two metrics named SM utilization ($SM_{util}$) and arithmetic intensity ($AI$).
Two metrics can be calculated as follows:
\begin{equation}\nonumber
    Block_{count}=\frac{F_N}{2 \times Warp_W} \times \frac{I_N \times I_H \times I_W}{2 \times Warp_H}
\end{equation}
\begin{equation}
    SM_{util}=\frac{Block_{count}}{Block_{num}\times SM_{num}}
    \label{fo:smutil}
\end{equation}
\begin{equation}
    AI = \frac{Warp_H \times T_{num}}{Warp_H+T_{num}}
    \label{fo:diff}
\end{equation}
where $Block_{count}$ is the number of generated thread blocks, $SM_{num}$ is the number of SMs on a GPU. For RTX 2080Ti and AGX Xavier, $SM_{num}=68$ and $SM_{num}=8$ respectively.

The whole workflow is described in Algorithm \ref{algo:pwalgo}.
We first choose the layout of output and partition the output into block tiles based on $F_N$ (Line 3).
Second, we choose the candidate set for $Warp_H$ based on $I_N \times I_H \times I_W$ (Lines 4).
Then we iterate over all combinations of $Warp_W$, $Warp_H$, $Warp_{num}$, $Block_{num}$ and $C_{num}$ (Line 6), and keep the combinations that satisfy the constraints $Limit_R$ (Formula \ref{fo:limitr}) and $Limit_S$ (Formula \ref{fo:limits}).

Next, we calculate values of $SM_{util}$ (Formula \ref{fo:smutil}) and $AI$ (Formula \ref{fo:diff}) for all satisfied combinations (Line 9) and select the optimal combination with following steps:
\begin{enumerate}[Step 1]
    \item If $SM_{util} \geq 1$ is true for all combinations, we select the combinations that possess the smallest and close to the smallest $SM_{util}$ (Lines 10-12).
    The reason is that when $SM_{util} \geq 1$, all SMs are utilized, in which case we want to reduce the number of thread blocks to reduce the number of loads of shared filters or inputs between multiple thread blocks.
    \item If there exists combinations such that $SM_{util}<1$, we first collect these combinations. Then, among collected combinations, we select the ones that possess the biggest and close to the biggest $SM_{util}$ (Lines 13-15).
    The reason is that when $SM_{util}<1$, there are idle SMs, in which case we want to increase $SM_{util}$ to fully utilize SMs. We do not want $SM_{util}$ to exceed 1 because that will incur more memory operations.
    \item Among candidate combinations selected in Step 1 and Step 2, we select the combination with the maximum value of $AI$ (Line 10, 13) because higher arithmetic intensity can hide more global memory access latency.
\end{enumerate}

Last, we choose the pointwise convolution kernel based on the selected combination (Line 16).
In this kernel, each thread block first loads $C_{num}$ channels of corresponding inputs and filters into a shared memory array (Line 20).
Meanwhile, the thread block loads the next $C_{num}$ channels into another shared memory array (Line 21).
We also use the double buffer method to increase the computational workload of each thread (Line 25).
The kernel repeats the process until all channels have been accumulated to output elements.
Finally, we use a warp level segmented parallel reduction to reduce results of different channels into the final result and write results to global memory (Line 26).
