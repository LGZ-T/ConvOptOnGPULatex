\section{Conclusion}
In this study, we proposed two reuse algorithms that can significantly reduce the number of memory transactions. We used CUDA shuffle
instructions and row reuse to eliminate column and row duplications , respectively. We also designed a method with pack and unpack instructions from the CUDA Toolkit to convert dynamic indexing into static indexing. The experiments applied on 2D and 3D convolutions confirmed that the proposed reuse algorithms  significantly improve the performance compared with other state-of-the-art libraries. Furthermore, the implementation of the proposed algorithms was derived from direct convolution, indicating that the performance was improved without incurring extra memory storage.%% Acknowledgmentsc
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}
