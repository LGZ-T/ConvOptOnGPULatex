\section{Conclusion}
In this work we propose two reuse algorithms which can significantly reduce the number of memory transactions. We use CUDA shuffle
instructions to eliminate column duplications and row reuse to eliminate row duplications. To convert dynamic indexing into static
indexing, we design a method with $pack$ and $unpack$ instructions provided by CUDA Toolkit. Experiments on 2D and 3D convolutions show
that our reuse algorithms significantly improve the performance compared with state-of-the-art libraries. Furthermore, our implementation
is derived from direct convolution, which means that we improve the performance without incurs extra memory storage.
%% Acknowledgmentsc
\begin{acks}                            %% acks environment is optional
                                        %% contents suppressed with 'anonymous'
  %% Commands \grantsponsor{<sponsorID>}{<name>}{<url>} and
  %% \grantnum[<url>]{<sponsorID>}{<number>} should be used to
  %% acknowledge financial support and will be used by metadata
  %% extraction tools.
  This material is based upon work supported by the
  \grantsponsor{GS100000001}{National Science
    Foundation}{http://dx.doi.org/10.13039/100000001} under Grant
  No.~\grantnum{GS100000001}{nnnnnnn} and Grant
  No.~\grantnum{GS100000001}{mmmmmmm}.  Any opinions, findings, and
  conclusions or recommendations expressed in this material are those
  of the author and do not necessarily reflect the views of the
  National Science Foundation.
\end{acks}
